# Notes
Useful repos
- vllm - https://github.com/vllm-project/vllm  
  Does not support ARM/ANE (only linux+x86 CPU, or specific NVIDIA GPU)

- ollama - https://github.com/ollama/ollama
- llamaFile - https://github.com/Mozilla-Ocho/llamafile
- llamaRag - https://github.com/Mozilla-Ocho/llamafile-rag-example
- llama.cpp - https://github.com/ggerganov/llama.cpp
- flash_attn - https://github.com/Dao-AILab/flash-attention     
    Requires nvcc
- accelerate - https://github.com/huggingface/accelerate  
   Does not support ANE
- openVINO - https://github.com/openvinotoolkit/openvino  
   OSS repo for model deployment/inference
